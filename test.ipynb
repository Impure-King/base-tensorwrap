{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.0.0.3', '0.0.0.2')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorwrap as tf\n",
    "from tensorwrap import torch\n",
    "tf.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.arange(1, 1000, 2)\n",
    "y_train = x_train + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  11,   13,   15,   17,   19,   21,   23,   25,   27,   29,   31,\n",
       "         33,   35,   37,   39,   41,   43,   45,   47,   49,   51,   53,\n",
       "         55,   57,   59,   61,   63,   65,   67,   69,   71,   73,   75,\n",
       "         77,   79,   81,   83,   85,   87,   89,   91,   93,   95,   97,\n",
       "         99,  101,  103,  105,  107,  109,  111,  113,  115,  117,  119,\n",
       "        121,  123,  125,  127,  129,  131,  133,  135,  137,  139,  141,\n",
       "        143,  145,  147,  149,  151,  153,  155,  157,  159,  161,  163,\n",
       "        165,  167,  169,  171,  173,  175,  177,  179,  181,  183,  185,\n",
       "        187,  189,  191,  193,  195,  197,  199,  201,  203,  205,  207,\n",
       "        209,  211,  213,  215,  217,  219,  221,  223,  225,  227,  229,\n",
       "        231,  233,  235,  237,  239,  241,  243,  245,  247,  249,  251,\n",
       "        253,  255,  257,  259,  261,  263,  265,  267,  269,  271,  273,\n",
       "        275,  277,  279,  281,  283,  285,  287,  289,  291,  293,  295,\n",
       "        297,  299,  301,  303,  305,  307,  309,  311,  313,  315,  317,\n",
       "        319,  321,  323,  325,  327,  329,  331,  333,  335,  337,  339,\n",
       "        341,  343,  345,  347,  349,  351,  353,  355,  357,  359,  361,\n",
       "        363,  365,  367,  369,  371,  373,  375,  377,  379,  381,  383,\n",
       "        385,  387,  389,  391,  393,  395,  397,  399,  401,  403,  405,\n",
       "        407,  409,  411,  413,  415,  417,  419,  421,  423,  425,  427,\n",
       "        429,  431,  433,  435,  437,  439,  441,  443,  445,  447,  449,\n",
       "        451,  453,  455,  457,  459,  461,  463,  465,  467,  469,  471,\n",
       "        473,  475,  477,  479,  481,  483,  485,  487,  489,  491,  493,\n",
       "        495,  497,  499,  501,  503,  505,  507,  509,  511,  513,  515,\n",
       "        517,  519,  521,  523,  525,  527,  529,  531,  533,  535,  537,\n",
       "        539,  541,  543,  545,  547,  549,  551,  553,  555,  557,  559,\n",
       "        561,  563,  565,  567,  569,  571,  573,  575,  577,  579,  581,\n",
       "        583,  585,  587,  589,  591,  593,  595,  597,  599,  601,  603,\n",
       "        605,  607,  609,  611,  613,  615,  617,  619,  621,  623,  625,\n",
       "        627,  629,  631,  633,  635,  637,  639,  641,  643,  645,  647,\n",
       "        649,  651,  653,  655,  657,  659,  661,  663,  665,  667,  669,\n",
       "        671,  673,  675,  677,  679,  681,  683,  685,  687,  689,  691,\n",
       "        693,  695,  697,  699,  701,  703,  705,  707,  709,  711,  713,\n",
       "        715,  717,  719,  721,  723,  725,  727,  729,  731,  733,  735,\n",
       "        737,  739,  741,  743,  745,  747,  749,  751,  753,  755,  757,\n",
       "        759,  761,  763,  765,  767,  769,  771,  773,  775,  777,  779,\n",
       "        781,  783,  785,  787,  789,  791,  793,  795,  797,  799,  801,\n",
       "        803,  805,  807,  809,  811,  813,  815,  817,  819,  821,  823,\n",
       "        825,  827,  829,  831,  833,  835,  837,  839,  841,  843,  845,\n",
       "        847,  849,  851,  853,  855,  857,  859,  861,  863,  865,  867,\n",
       "        869,  871,  873,  875,  877,  879,  881,  883,  885,  887,  889,\n",
       "        891,  893,  895,  897,  899,  901,  903,  905,  907,  909,  911,\n",
       "        913,  915,  917,  919,  921,  923,  925,  927,  929,  931,  933,\n",
       "        935,  937,  939,  941,  943,  945,  947,  949,  951,  953,  955,\n",
       "        957,  959,  961,  963,  965,  967,  969,  971,  973,  975,  977,\n",
       "        979,  981,  983,  985,  987,  989,  991,  993,  995,  997,  999,\n",
       "       1001, 1003, 1005, 1007, 1009], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the axis:\n",
    "x_train = torch.reshape(x_train, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  1],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  7],\n",
       "       [  9],\n",
       "       [ 11],\n",
       "       [ 13],\n",
       "       [ 15],\n",
       "       [ 17],\n",
       "       [ 19],\n",
       "       [ 21],\n",
       "       [ 23],\n",
       "       [ 25],\n",
       "       [ 27],\n",
       "       [ 29],\n",
       "       [ 31],\n",
       "       [ 33],\n",
       "       [ 35],\n",
       "       [ 37],\n",
       "       [ 39],\n",
       "       [ 41],\n",
       "       [ 43],\n",
       "       [ 45],\n",
       "       [ 47],\n",
       "       [ 49],\n",
       "       [ 51],\n",
       "       [ 53],\n",
       "       [ 55],\n",
       "       [ 57],\n",
       "       [ 59],\n",
       "       [ 61],\n",
       "       [ 63],\n",
       "       [ 65],\n",
       "       [ 67],\n",
       "       [ 69],\n",
       "       [ 71],\n",
       "       [ 73],\n",
       "       [ 75],\n",
       "       [ 77],\n",
       "       [ 79],\n",
       "       [ 81],\n",
       "       [ 83],\n",
       "       [ 85],\n",
       "       [ 87],\n",
       "       [ 89],\n",
       "       [ 91],\n",
       "       [ 93],\n",
       "       [ 95],\n",
       "       [ 97],\n",
       "       [ 99],\n",
       "       [101],\n",
       "       [103],\n",
       "       [105],\n",
       "       [107],\n",
       "       [109],\n",
       "       [111],\n",
       "       [113],\n",
       "       [115],\n",
       "       [117],\n",
       "       [119],\n",
       "       [121],\n",
       "       [123],\n",
       "       [125],\n",
       "       [127],\n",
       "       [129],\n",
       "       [131],\n",
       "       [133],\n",
       "       [135],\n",
       "       [137],\n",
       "       [139],\n",
       "       [141],\n",
       "       [143],\n",
       "       [145],\n",
       "       [147],\n",
       "       [149],\n",
       "       [151],\n",
       "       [153],\n",
       "       [155],\n",
       "       [157],\n",
       "       [159],\n",
       "       [161],\n",
       "       [163],\n",
       "       [165],\n",
       "       [167],\n",
       "       [169],\n",
       "       [171],\n",
       "       [173],\n",
       "       [175],\n",
       "       [177],\n",
       "       [179],\n",
       "       [181],\n",
       "       [183],\n",
       "       [185],\n",
       "       [187],\n",
       "       [189],\n",
       "       [191],\n",
       "       [193],\n",
       "       [195],\n",
       "       [197],\n",
       "       [199],\n",
       "       [201],\n",
       "       [203],\n",
       "       [205],\n",
       "       [207],\n",
       "       [209],\n",
       "       [211],\n",
       "       [213],\n",
       "       [215],\n",
       "       [217],\n",
       "       [219],\n",
       "       [221],\n",
       "       [223],\n",
       "       [225],\n",
       "       [227],\n",
       "       [229],\n",
       "       [231],\n",
       "       [233],\n",
       "       [235],\n",
       "       [237],\n",
       "       [239],\n",
       "       [241],\n",
       "       [243],\n",
       "       [245],\n",
       "       [247],\n",
       "       [249],\n",
       "       [251],\n",
       "       [253],\n",
       "       [255],\n",
       "       [257],\n",
       "       [259],\n",
       "       [261],\n",
       "       [263],\n",
       "       [265],\n",
       "       [267],\n",
       "       [269],\n",
       "       [271],\n",
       "       [273],\n",
       "       [275],\n",
       "       [277],\n",
       "       [279],\n",
       "       [281],\n",
       "       [283],\n",
       "       [285],\n",
       "       [287],\n",
       "       [289],\n",
       "       [291],\n",
       "       [293],\n",
       "       [295],\n",
       "       [297],\n",
       "       [299],\n",
       "       [301],\n",
       "       [303],\n",
       "       [305],\n",
       "       [307],\n",
       "       [309],\n",
       "       [311],\n",
       "       [313],\n",
       "       [315],\n",
       "       [317],\n",
       "       [319],\n",
       "       [321],\n",
       "       [323],\n",
       "       [325],\n",
       "       [327],\n",
       "       [329],\n",
       "       [331],\n",
       "       [333],\n",
       "       [335],\n",
       "       [337],\n",
       "       [339],\n",
       "       [341],\n",
       "       [343],\n",
       "       [345],\n",
       "       [347],\n",
       "       [349],\n",
       "       [351],\n",
       "       [353],\n",
       "       [355],\n",
       "       [357],\n",
       "       [359],\n",
       "       [361],\n",
       "       [363],\n",
       "       [365],\n",
       "       [367],\n",
       "       [369],\n",
       "       [371],\n",
       "       [373],\n",
       "       [375],\n",
       "       [377],\n",
       "       [379],\n",
       "       [381],\n",
       "       [383],\n",
       "       [385],\n",
       "       [387],\n",
       "       [389],\n",
       "       [391],\n",
       "       [393],\n",
       "       [395],\n",
       "       [397],\n",
       "       [399],\n",
       "       [401],\n",
       "       [403],\n",
       "       [405],\n",
       "       [407],\n",
       "       [409],\n",
       "       [411],\n",
       "       [413],\n",
       "       [415],\n",
       "       [417],\n",
       "       [419],\n",
       "       [421],\n",
       "       [423],\n",
       "       [425],\n",
       "       [427],\n",
       "       [429],\n",
       "       [431],\n",
       "       [433],\n",
       "       [435],\n",
       "       [437],\n",
       "       [439],\n",
       "       [441],\n",
       "       [443],\n",
       "       [445],\n",
       "       [447],\n",
       "       [449],\n",
       "       [451],\n",
       "       [453],\n",
       "       [455],\n",
       "       [457],\n",
       "       [459],\n",
       "       [461],\n",
       "       [463],\n",
       "       [465],\n",
       "       [467],\n",
       "       [469],\n",
       "       [471],\n",
       "       [473],\n",
       "       [475],\n",
       "       [477],\n",
       "       [479],\n",
       "       [481],\n",
       "       [483],\n",
       "       [485],\n",
       "       [487],\n",
       "       [489],\n",
       "       [491],\n",
       "       [493],\n",
       "       [495],\n",
       "       [497],\n",
       "       [499],\n",
       "       [501],\n",
       "       [503],\n",
       "       [505],\n",
       "       [507],\n",
       "       [509],\n",
       "       [511],\n",
       "       [513],\n",
       "       [515],\n",
       "       [517],\n",
       "       [519],\n",
       "       [521],\n",
       "       [523],\n",
       "       [525],\n",
       "       [527],\n",
       "       [529],\n",
       "       [531],\n",
       "       [533],\n",
       "       [535],\n",
       "       [537],\n",
       "       [539],\n",
       "       [541],\n",
       "       [543],\n",
       "       [545],\n",
       "       [547],\n",
       "       [549],\n",
       "       [551],\n",
       "       [553],\n",
       "       [555],\n",
       "       [557],\n",
       "       [559],\n",
       "       [561],\n",
       "       [563],\n",
       "       [565],\n",
       "       [567],\n",
       "       [569],\n",
       "       [571],\n",
       "       [573],\n",
       "       [575],\n",
       "       [577],\n",
       "       [579],\n",
       "       [581],\n",
       "       [583],\n",
       "       [585],\n",
       "       [587],\n",
       "       [589],\n",
       "       [591],\n",
       "       [593],\n",
       "       [595],\n",
       "       [597],\n",
       "       [599],\n",
       "       [601],\n",
       "       [603],\n",
       "       [605],\n",
       "       [607],\n",
       "       [609],\n",
       "       [611],\n",
       "       [613],\n",
       "       [615],\n",
       "       [617],\n",
       "       [619],\n",
       "       [621],\n",
       "       [623],\n",
       "       [625],\n",
       "       [627],\n",
       "       [629],\n",
       "       [631],\n",
       "       [633],\n",
       "       [635],\n",
       "       [637],\n",
       "       [639],\n",
       "       [641],\n",
       "       [643],\n",
       "       [645],\n",
       "       [647],\n",
       "       [649],\n",
       "       [651],\n",
       "       [653],\n",
       "       [655],\n",
       "       [657],\n",
       "       [659],\n",
       "       [661],\n",
       "       [663],\n",
       "       [665],\n",
       "       [667],\n",
       "       [669],\n",
       "       [671],\n",
       "       [673],\n",
       "       [675],\n",
       "       [677],\n",
       "       [679],\n",
       "       [681],\n",
       "       [683],\n",
       "       [685],\n",
       "       [687],\n",
       "       [689],\n",
       "       [691],\n",
       "       [693],\n",
       "       [695],\n",
       "       [697],\n",
       "       [699],\n",
       "       [701],\n",
       "       [703],\n",
       "       [705],\n",
       "       [707],\n",
       "       [709],\n",
       "       [711],\n",
       "       [713],\n",
       "       [715],\n",
       "       [717],\n",
       "       [719],\n",
       "       [721],\n",
       "       [723],\n",
       "       [725],\n",
       "       [727],\n",
       "       [729],\n",
       "       [731],\n",
       "       [733],\n",
       "       [735],\n",
       "       [737],\n",
       "       [739],\n",
       "       [741],\n",
       "       [743],\n",
       "       [745],\n",
       "       [747],\n",
       "       [749],\n",
       "       [751],\n",
       "       [753],\n",
       "       [755],\n",
       "       [757],\n",
       "       [759],\n",
       "       [761],\n",
       "       [763],\n",
       "       [765],\n",
       "       [767],\n",
       "       [769],\n",
       "       [771],\n",
       "       [773],\n",
       "       [775],\n",
       "       [777],\n",
       "       [779],\n",
       "       [781],\n",
       "       [783],\n",
       "       [785],\n",
       "       [787],\n",
       "       [789],\n",
       "       [791],\n",
       "       [793],\n",
       "       [795],\n",
       "       [797],\n",
       "       [799],\n",
       "       [801],\n",
       "       [803],\n",
       "       [805],\n",
       "       [807],\n",
       "       [809],\n",
       "       [811],\n",
       "       [813],\n",
       "       [815],\n",
       "       [817],\n",
       "       [819],\n",
       "       [821],\n",
       "       [823],\n",
       "       [825],\n",
       "       [827],\n",
       "       [829],\n",
       "       [831],\n",
       "       [833],\n",
       "       [835],\n",
       "       [837],\n",
       "       [839],\n",
       "       [841],\n",
       "       [843],\n",
       "       [845],\n",
       "       [847],\n",
       "       [849],\n",
       "       [851],\n",
       "       [853],\n",
       "       [855],\n",
       "       [857],\n",
       "       [859],\n",
       "       [861],\n",
       "       [863],\n",
       "       [865],\n",
       "       [867],\n",
       "       [869],\n",
       "       [871],\n",
       "       [873],\n",
       "       [875],\n",
       "       [877],\n",
       "       [879],\n",
       "       [881],\n",
       "       [883],\n",
       "       [885],\n",
       "       [887],\n",
       "       [889],\n",
       "       [891],\n",
       "       [893],\n",
       "       [895],\n",
       "       [897],\n",
       "       [899],\n",
       "       [901],\n",
       "       [903],\n",
       "       [905],\n",
       "       [907],\n",
       "       [909],\n",
       "       [911],\n",
       "       [913],\n",
       "       [915],\n",
       "       [917],\n",
       "       [919],\n",
       "       [921],\n",
       "       [923],\n",
       "       [925],\n",
       "       [927],\n",
       "       [929],\n",
       "       [931],\n",
       "       [933],\n",
       "       [935],\n",
       "       [937],\n",
       "       [939],\n",
       "       [941],\n",
       "       [943],\n",
       "       [945],\n",
       "       [947],\n",
       "       [949],\n",
       "       [951],\n",
       "       [953],\n",
       "       [955],\n",
       "       [957],\n",
       "       [959],\n",
       "       [961],\n",
       "       [963],\n",
       "       [965],\n",
       "       [967],\n",
       "       [969],\n",
       "       [971],\n",
       "       [973],\n",
       "       [975],\n",
       "       [977],\n",
       "       [979],\n",
       "       [981],\n",
       "       [983],\n",
       "       [985],\n",
       "       [987],\n",
       "       [989],\n",
       "       [991],\n",
       "       [993],\n",
       "       [995],\n",
       "       [997],\n",
       "       [999]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.layers.Linear(units = 1, input_shape = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential([\n",
    "    layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model:\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MSE,\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "    accuracy = tf.keras.losses.MAE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got int32. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train \u001b[39m=\u001b[39;49m x_train, y_train \u001b[39m=\u001b[39;49m y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/base-tensorwrap/tensorwrap/torch/nn/models/sequential.py:23\u001b[0m, in \u001b[0;36mSequential.fit\u001b[0;34m(self, x_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, x_train, y_train, epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(Model \u001b[39m=\u001b[39;49m Sequential, x_train\u001b[39m=\u001b[39;49mx_train, y_train\u001b[39m=\u001b[39;49my_train, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[0;32m~/Documents/GitHub/base-tensorwrap/tensorwrap/torch/nn/models/modules.py:69\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, Model, x_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     67\u001b[0m y_pred \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x_train)\n\u001b[1;32m     68\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracy(y_train, y_pred)\n\u001b[0;32m---> 69\u001b[0m Model\u001b[39m.\u001b[39;49mtrain_step(\u001b[39mself\u001b[39;49m, y_train, y_pred)\n\u001b[1;32m     70\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m : Loss = \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/base-tensorwrap/tensorwrap/torch/nn/models/modules.py:60\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred):\n\u001b[1;32m     59\u001b[0m     derivative_fn \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mgrad(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn)\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mcompute_grads(derivative_fn, y_true, y_pred)\n\u001b[1;32m     61\u001b[0m     weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(Model\u001b[39m.\u001b[39mtrainable_weights(\u001b[39mself\u001b[39m))\n\u001b[1;32m     62\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[0;32m~/Documents/GitHub/base-tensorwrap/tensorwrap/keras/optimizers.py:26\u001b[0m, in \u001b[0;36mSGD.compute_grads\u001b[0;34m(self, loss_fn, y_true, y_pred)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_grads\u001b[39m(\u001b[39mself\u001b[39m, loss_fn, y_true, y_pred):\n\u001b[1;32m     25\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrads \u001b[39m=\u001b[39m loss_fn(y_true, y_pred)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/TensorWrap/lib/python3.10/site-packages/jax/_src/api.py:1206\u001b[0m, in \u001b[0;36m_check_input_dtype_revderiv\u001b[0;34m(name, holomorphic, allow_int, x)\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[39mif\u001b[39;00m (dtypes\u001b[39m.\u001b[39missubdtype(aval\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m     dtypes\u001b[39m.\u001b[39missubdtype(aval\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mbool_)):\n\u001b[1;32m   1205\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_int:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m requires real- or complex-valued inputs (input dtype \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1207\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthat is a sub-dtype of np.inexact), but got \u001b[39m\u001b[39m{\u001b[39;00maval\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1208\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mIf you want to use Boolean- or integer-valued inputs, use vjp \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mor set allow_int to True.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1210\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(aval\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minexact):\n\u001b[1;32m   1211\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m requires numerical-valued inputs (input dtype that is a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1212\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msub-dtype of np.bool_ or np.number), but got \u001b[39m\u001b[39m{\u001b[39;00maval\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got int32. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True."
     ]
    }
   ],
   "source": [
    "model.fit(x_train = x_train, y_train = y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1890.0881, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__call__(tf.Variable([99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1, 2, 3, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.Array"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.jax.Array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorWrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "087f40dff4324d7cfdf533de6cd08d0a5078eb4230684a53bb35630ba5e75359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
