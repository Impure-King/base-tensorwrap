{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.0.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorwrap as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.range(start = 1, end = 1000, delta = 2)\n",
    "y_train = x_train + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  11.,   13.,   15.,   17.,   19.,   21.,   23.,   25.,   27.,\n",
       "         29.,   31.,   33.,   35.,   37.,   39.,   41.,   43.,   45.,\n",
       "         47.,   49.,   51.,   53.,   55.,   57.,   59.,   61.,   63.,\n",
       "         65.,   67.,   69.,   71.,   73.,   75.,   77.,   79.,   81.,\n",
       "         83.,   85.,   87.,   89.,   91.,   93.,   95.,   97.,   99.,\n",
       "        101.,  103.,  105.,  107.,  109.,  111.,  113.,  115.,  117.,\n",
       "        119.,  121.,  123.,  125.,  127.,  129.,  131.,  133.,  135.,\n",
       "        137.,  139.,  141.,  143.,  145.,  147.,  149.,  151.,  153.,\n",
       "        155.,  157.,  159.,  161.,  163.,  165.,  167.,  169.,  171.,\n",
       "        173.,  175.,  177.,  179.,  181.,  183.,  185.,  187.,  189.,\n",
       "        191.,  193.,  195.,  197.,  199.,  201.,  203.,  205.,  207.,\n",
       "        209.,  211.,  213.,  215.,  217.,  219.,  221.,  223.,  225.,\n",
       "        227.,  229.,  231.,  233.,  235.,  237.,  239.,  241.,  243.,\n",
       "        245.,  247.,  249.,  251.,  253.,  255.,  257.,  259.,  261.,\n",
       "        263.,  265.,  267.,  269.,  271.,  273.,  275.,  277.,  279.,\n",
       "        281.,  283.,  285.,  287.,  289.,  291.,  293.,  295.,  297.,\n",
       "        299.,  301.,  303.,  305.,  307.,  309.,  311.,  313.,  315.,\n",
       "        317.,  319.,  321.,  323.,  325.,  327.,  329.,  331.,  333.,\n",
       "        335.,  337.,  339.,  341.,  343.,  345.,  347.,  349.,  351.,\n",
       "        353.,  355.,  357.,  359.,  361.,  363.,  365.,  367.,  369.,\n",
       "        371.,  373.,  375.,  377.,  379.,  381.,  383.,  385.,  387.,\n",
       "        389.,  391.,  393.,  395.,  397.,  399.,  401.,  403.,  405.,\n",
       "        407.,  409.,  411.,  413.,  415.,  417.,  419.,  421.,  423.,\n",
       "        425.,  427.,  429.,  431.,  433.,  435.,  437.,  439.,  441.,\n",
       "        443.,  445.,  447.,  449.,  451.,  453.,  455.,  457.,  459.,\n",
       "        461.,  463.,  465.,  467.,  469.,  471.,  473.,  475.,  477.,\n",
       "        479.,  481.,  483.,  485.,  487.,  489.,  491.,  493.,  495.,\n",
       "        497.,  499.,  501.,  503.,  505.,  507.,  509.,  511.,  513.,\n",
       "        515.,  517.,  519.,  521.,  523.,  525.,  527.,  529.,  531.,\n",
       "        533.,  535.,  537.,  539.,  541.,  543.,  545.,  547.,  549.,\n",
       "        551.,  553.,  555.,  557.,  559.,  561.,  563.,  565.,  567.,\n",
       "        569.,  571.,  573.,  575.,  577.,  579.,  581.,  583.,  585.,\n",
       "        587.,  589.,  591.,  593.,  595.,  597.,  599.,  601.,  603.,\n",
       "        605.,  607.,  609.,  611.,  613.,  615.,  617.,  619.,  621.,\n",
       "        623.,  625.,  627.,  629.,  631.,  633.,  635.,  637.,  639.,\n",
       "        641.,  643.,  645.,  647.,  649.,  651.,  653.,  655.,  657.,\n",
       "        659.,  661.,  663.,  665.,  667.,  669.,  671.,  673.,  675.,\n",
       "        677.,  679.,  681.,  683.,  685.,  687.,  689.,  691.,  693.,\n",
       "        695.,  697.,  699.,  701.,  703.,  705.,  707.,  709.,  711.,\n",
       "        713.,  715.,  717.,  719.,  721.,  723.,  725.,  727.,  729.,\n",
       "        731.,  733.,  735.,  737.,  739.,  741.,  743.,  745.,  747.,\n",
       "        749.,  751.,  753.,  755.,  757.,  759.,  761.,  763.,  765.,\n",
       "        767.,  769.,  771.,  773.,  775.,  777.,  779.,  781.,  783.,\n",
       "        785.,  787.,  789.,  791.,  793.,  795.,  797.,  799.,  801.,\n",
       "        803.,  805.,  807.,  809.,  811.,  813.,  815.,  817.,  819.,\n",
       "        821.,  823.,  825.,  827.,  829.,  831.,  833.,  835.,  837.,\n",
       "        839.,  841.,  843.,  845.,  847.,  849.,  851.,  853.,  855.,\n",
       "        857.,  859.,  861.,  863.,  865.,  867.,  869.,  871.,  873.,\n",
       "        875.,  877.,  879.,  881.,  883.,  885.,  887.,  889.,  891.,\n",
       "        893.,  895.,  897.,  899.,  901.,  903.,  905.,  907.,  909.,\n",
       "        911.,  913.,  915.,  917.,  919.,  921.,  923.,  925.,  927.,\n",
       "        929.,  931.,  933.,  935.,  937.,  939.,  941.,  943.,  945.,\n",
       "        947.,  949.,  951.,  953.,  955.,  957.,  959.,  961.,  963.,\n",
       "        965.,  967.,  969.,  971.,  973.,  975.,  977.,  979.,  981.,\n",
       "        983.,  985.,  987.,  989.,  991.,  993.,  995.,  997.,  999.,\n",
       "       1001., 1003., 1005., 1007., 1009.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding the axis:\n",
    "x_train = tf.expand_dims(x_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(units = 1, input_shape = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 06:12:53.738807: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2163] Execution of replica 0 failed: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.custom_call' failed: jaxlib/gpu/prng_kernels.cc:33: operation gpuGetLastError() failed: out of memory.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.custom_call' failed: jaxlib/gpu/prng_kernels.cc:33: operation gpuGetLastError() failed: out of memory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Compiling the model:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mcompile(\n\u001b[1;32m      3\u001b[0m     loss \u001b[39m=\u001b[39;49m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mMSE,\n\u001b[1;32m      4\u001b[0m     optimizer \u001b[39m=\u001b[39;49m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mSGD(learning_rate \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m     accuracy \u001b[39m=\u001b[39;49m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mMAE\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/base-tensorwrap/tensorwrap/keras/models/modules.py:56\u001b[0m, in \u001b[0;36mModel.compile\u001b[0;34m(self, loss, optimizer, accuracy)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracy \u001b[39m=\u001b[39m accuracy\n\u001b[1;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 56\u001b[0m     layer\u001b[39m.\u001b[39;49mbuild([\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/GitHub/base-tensorwrap/tensorwrap/keras/layers.py:44\u001b[0m, in \u001b[0;36mDense.build\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, shape):\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49madd_weight(\u001b[39mself\u001b[39;49m, shape \u001b[39m=\u001b[39;49m [shape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munits])\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39madd_weight(\u001b[39mself\u001b[39m, initializer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_initializer, shape \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits])\n\u001b[1;32m     46\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mbuild()\n",
      "File \u001b[0;32m~/GitHub/base-tensorwrap/tensorwrap/self.py:12\u001b[0m, in \u001b[0;36madd_weight\u001b[0;34m(self, shape, dtype, trainable, initializer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Uncomment once the initializer is made:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# self.initializer = initializers.get(initializer)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m initializer \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39marray(jax\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mnormal(key, (shape), dtype \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[1;32m     13\u001b[0m \u001b[39melif\u001b[39;00m initializer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39marray(jnp\u001b[39m.\u001b[39mzeros((shape), dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype))\n",
      "File \u001b[0;32m~/miniconda3/envs/TensorWrap/lib/python3.10/site-packages/jax/_src/random.py:562\u001b[0m, in \u001b[0;36mnormal\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    560\u001b[0m dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[1;32m    561\u001b[0m shape \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mas_named_shape(shape)\n\u001b[0;32m--> 562\u001b[0m \u001b[39mreturn\u001b[39;00m _normal(key, shape, dtype)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/TensorWrap/lib/python3.10/site-packages/jax/interpreters/pxla.py:2136\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   2134\u001b[0m   out_bufs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_with_tokens(input_bufs)\n\u001b[1;32m   2135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2136\u001b[0m   out_bufs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxla_executable\u001b[39m.\u001b[39;49mexecute_sharded_on_local_devices(\n\u001b[1;32m   2137\u001b[0m       input_bufs)\n\u001b[1;32m   2138\u001b[0m \u001b[39mif\u001b[39;00m dispatch\u001b[39m.\u001b[39mneeds_check_special():\n\u001b[1;32m   2139\u001b[0m   \u001b[39mfor\u001b[39;00m bufs \u001b[39min\u001b[39;00m out_bufs:\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.custom_call' failed: jaxlib/gpu/prng_kernels.cc:33: operation gpuGetLastError() failed: out of memory."
     ]
    }
   ],
   "source": [
    "# Compiling the model:\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MSE,\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "    accuracy = tf.keras.losses.MAE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss = 509.8795471191406\n",
      "Epoch 1 : Loss = 509.063720703125\n",
      "Epoch 2 : Loss = 508.24920654296875\n",
      "Epoch 3 : Loss = 507.43609619140625\n",
      "Epoch 4 : Loss = 506.62408447265625\n",
      "Epoch 5 : Loss = 505.81353759765625\n",
      "Epoch 6 : Loss = 505.0043029785156\n",
      "Epoch 7 : Loss = 504.1962890625\n",
      "Epoch 8 : Loss = 503.38958740234375\n",
      "Epoch 9 : Loss = 502.5840759277344\n",
      "Epoch 10 : Loss = 501.77996826171875\n",
      "Epoch 11 : Loss = 500.9770812988281\n",
      "Epoch 12 : Loss = 500.1756286621094\n",
      "Epoch 13 : Loss = 499.3752136230469\n",
      "Epoch 14 : Loss = 498.5762634277344\n",
      "Epoch 15 : Loss = 497.7785339355469\n",
      "Epoch 16 : Loss = 496.9821472167969\n",
      "Epoch 17 : Loss = 496.18695068359375\n",
      "Epoch 18 : Loss = 495.3930358886719\n",
      "Epoch 19 : Loss = 494.6004638671875\n",
      "Epoch 20 : Loss = 493.8090515136719\n",
      "Epoch 21 : Loss = 493.01898193359375\n",
      "Epoch 22 : Loss = 492.2301025390625\n",
      "Epoch 23 : Loss = 491.44256591796875\n",
      "Epoch 24 : Loss = 490.6562805175781\n",
      "Epoch 25 : Loss = 489.8711853027344\n",
      "Epoch 26 : Loss = 489.08740234375\n",
      "Epoch 27 : Loss = 488.30487060546875\n",
      "Epoch 28 : Loss = 487.5235290527344\n",
      "Epoch 29 : Loss = 486.74359130859375\n",
      "Epoch 30 : Loss = 485.9648132324219\n",
      "Epoch 31 : Loss = 485.1872253417969\n",
      "Epoch 32 : Loss = 484.41094970703125\n",
      "Epoch 33 : Loss = 483.6358337402344\n",
      "Epoch 34 : Loss = 482.86199951171875\n",
      "Epoch 35 : Loss = 482.08941650390625\n",
      "Epoch 36 : Loss = 481.3182067871094\n",
      "Epoch 37 : Loss = 480.5479736328125\n",
      "Epoch 38 : Loss = 479.7791442871094\n",
      "Epoch 39 : Loss = 479.0115661621094\n",
      "Epoch 40 : Loss = 478.2451171875\n",
      "Epoch 41 : Loss = 477.47991943359375\n",
      "Epoch 42 : Loss = 476.71588134765625\n",
      "Epoch 43 : Loss = 475.9531555175781\n",
      "Epoch 44 : Loss = 475.1916198730469\n",
      "Epoch 45 : Loss = 474.4312744140625\n",
      "Epoch 46 : Loss = 473.6722717285156\n",
      "Epoch 47 : Loss = 472.9143981933594\n",
      "Epoch 48 : Loss = 472.15771484375\n",
      "Epoch 49 : Loss = 471.4023132324219\n",
      "Epoch 50 : Loss = 470.64801025390625\n",
      "Epoch 51 : Loss = 469.8949890136719\n",
      "Epoch 52 : Loss = 469.14312744140625\n",
      "Epoch 53 : Loss = 468.39251708984375\n",
      "Epoch 54 : Loss = 467.6430969238281\n",
      "Epoch 55 : Loss = 466.8948669433594\n",
      "Epoch 56 : Loss = 466.14788818359375\n",
      "Epoch 57 : Loss = 465.40191650390625\n",
      "Epoch 58 : Loss = 464.6573486328125\n",
      "Epoch 59 : Loss = 463.9139404296875\n",
      "Epoch 60 : Loss = 463.1717224121094\n",
      "Epoch 61 : Loss = 462.4305725097656\n",
      "Epoch 62 : Loss = 461.6906433105469\n",
      "Epoch 63 : Loss = 460.9520263671875\n",
      "Epoch 64 : Loss = 460.21441650390625\n",
      "Epoch 65 : Loss = 459.47808837890625\n",
      "Epoch 66 : Loss = 458.7430114746094\n",
      "Epoch 67 : Loss = 458.0089111328125\n",
      "Epoch 68 : Loss = 457.27618408203125\n",
      "Epoch 69 : Loss = 456.5444641113281\n",
      "Epoch 70 : Loss = 455.8139953613281\n",
      "Epoch 71 : Loss = 455.08477783203125\n",
      "Epoch 72 : Loss = 454.35650634765625\n",
      "Epoch 73 : Loss = 453.6295471191406\n",
      "Epoch 74 : Loss = 452.9038391113281\n",
      "Epoch 75 : Loss = 452.17919921875\n",
      "Epoch 76 : Loss = 451.45562744140625\n",
      "Epoch 77 : Loss = 450.73333740234375\n",
      "Epoch 78 : Loss = 450.0121765136719\n",
      "Epoch 79 : Loss = 449.2920837402344\n",
      "Epoch 80 : Loss = 448.5732727050781\n",
      "Epoch 81 : Loss = 447.85552978515625\n",
      "Epoch 82 : Loss = 447.1390075683594\n",
      "Epoch 83 : Loss = 446.42352294921875\n",
      "Epoch 84 : Loss = 445.7093200683594\n",
      "Epoch 85 : Loss = 444.99615478515625\n",
      "Epoch 86 : Loss = 444.2841796875\n",
      "Epoch 87 : Loss = 443.57330322265625\n",
      "Epoch 88 : Loss = 442.8636169433594\n",
      "Epoch 89 : Loss = 442.1549987792969\n",
      "Epoch 90 : Loss = 441.447509765625\n",
      "Epoch 91 : Loss = 440.7412109375\n",
      "Epoch 92 : Loss = 440.03607177734375\n",
      "Epoch 93 : Loss = 439.33203125\n",
      "Epoch 94 : Loss = 438.6290283203125\n",
      "Epoch 95 : Loss = 437.9272766113281\n",
      "Epoch 96 : Loss = 437.2265930175781\n",
      "Epoch 97 : Loss = 436.5269775390625\n",
      "Epoch 98 : Loss = 435.8285827636719\n",
      "Epoch 99 : Loss = 435.1312561035156\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train = x_train, y_train = y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1890.0881, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__call__(tf.Variable([99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1, 2, 3, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.Array"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.jax.Array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorWrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da53633a286fdc5fa9862d67a3a85a7eec918dfea906e3018d3e6a5fef740b93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
